version: '3.8'

services:
  tokamak-ai-api:
    build: .
    container_name: tokamak-ai-api-server
    # Expose port directly in development, or through nginx in production
    expose:
      - "8000"
    ports:
      # Direct access in development (when nginx profile not used)
      - "${API_PORT:-8000}:8000"
    environment:
      - HOST=0.0.0.0
      - PORT=8000
      - WORKERS=4
      - OLLAMA_SERVERS=${OLLAMA_SERVERS:-http://host.docker.internal:11434}
      - DATABASE_URL=sqlite+aiosqlite:////app/data/tokamak_ai_api.db
      - SECRET_KEY=${SECRET_KEY:-change-this-secret-key}
      - DEFAULT_RATE_LIMIT=1000
      - RATE_LIMIT_WINDOW=3600
      - LOG_LEVEL=INFO
    restart: unless-stopped
    volumes:
      - ./logs:/var/log/tokamak-ai-api
      - ./data:/app/data
    networks:
      - tokamak-network

  # Nginx reverse proxy (production only)
  # Usage: docker-compose --profile production up -d
  nginx:
    image: nginx:alpine
    container_name: tokamak-ai-api-nginx
    profiles:
      - production
    ports:
      - "${NGINX_HTTP_PORT:-80}:80"
      - "${NGINX_HTTPS_PORT:-443}:443"
    volumes:
      - ./config/nginx-config.conf:/etc/nginx/conf.d/default.conf:ro
      - ./logs/nginx:/var/log/nginx
      # SSL certificates (if using HTTPS)
      # - ./ssl:/etc/nginx/ssl:ro
    depends_on:
      - tokamak-ai-api
    restart: unless-stopped
    networks:
      - tokamak-network

volumes:

networks:
  tokamak-network:
    driver: bridge
